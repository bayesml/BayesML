
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>bayesml.metatree package &#8212; BayesML</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css?v=ad100702" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=385a908f"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bayesml.metatree';</script>
    <link rel="icon" href="_static/BayesML_favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="bayesml.multivariate_normal package" href="bayesml.multivariate_normal.html" />
    <link rel="prev" title="bayesml.linearregression package" href="bayesml.linearregression.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>
<aside class="bd-header-announcement" aria-label="Announcement">
  <div class="bd-header-announcement__content">Our algorithm for the meta-tree model is accepted at AISTATS 2025! Click <a href='https://bayesml.github.io/BayesML/en/examples/metatree_prediction_interval.html'>here</a>!</div>
</aside>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/BayesML_logo.png" class="logo__image only-light" alt="BayesML - Home"/>
    <script>document.write(`<img src="_static/BayesML_logo.png" class="logo__image only-dark" alt="BayesML - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><div style="text-align:center">
  <span><i class="fas fa-globe"></i> Language:</span>
  <a href="../en/bayesml.metatree.html" class="language-link active" lang="en">English</a> / 
  <a href="../ja/bayesml.metatree.html" class="language-link" lang="ja">日本語</a>
</div></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="bayesml.html">Bayesml packages</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="bayesml.autoregressive.html">bayesml.autoregressive package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.bernoulli.html">bayesml.bernoulli package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.categorical.html">bayesml.categorical package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.contexttree.html">bayesml.contexttree package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.exponential.html">bayesml.exponential package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.gaussianmixture.html">bayesml.gaussianmixture package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.hiddenmarkovnormal.html">bayesml.hiddenmarkovnormal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.linearregression.html">bayesml.linearregression package</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">bayesml.metatree package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.multivariate_normal.html">bayesml.multivariate_normal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.normal.html">bayesml.normal package</a></li>
<li class="toctree-l2"><a class="reference internal" href="bayesml.poisson.html">bayesml.poisson package</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="examples/metatree_prediction_interval.html">Prediction interval calculation by <code class="docutils literal notranslate"><span class="pre">bayesml.metatree</span></code> (accepted at AISTATS 2025)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="developers.html">BayesML Developers</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/bayesml/BayesML" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/bayesml.metatree.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>bayesml.metatree package</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-bayesml.metatree">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-data-generative-model">Stochastic Data Generative Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-distribution">Prior Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-distribution">Posterior Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation-by-mtrf">Approximation by MTRF</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation-by-mtmcmc">Approximation by MTMCMC</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel"><code class="docutils literal notranslate"><span class="pre">GenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_constants"><code class="docutils literal notranslate"><span class="pre">GenModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.set_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.gen_params"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.set_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.gen_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.save_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.save_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.visualize_model"><code class="docutils literal notranslate"><span class="pre">GenModel.visualize_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel"><code class="docutils literal notranslate"><span class="pre">LearnModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_constants"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.set_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.set_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.update_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.update_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.estimate_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.visualize_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.visualize_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_p_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_p_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_dist"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_dist()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.make_prediction"><code class="docutils literal notranslate"><span class="pre">LearnModel.make_prediction()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.pred_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.pred_and_update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_var"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_var()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_feature_importances"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_feature_importances()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_density"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_density()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.fit"><code class="docutils literal notranslate"><span class="pre">LearnModel.fit()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.predict"><code class="docutils literal notranslate"><span class="pre">LearnModel.predict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.predict_proba"><code class="docutils literal notranslate"><span class="pre">LearnModel.predict_proba()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="bayesml-metatree-package">
<h1>bayesml.metatree package<a class="headerlink" href="#bayesml-metatree-package" title="Link to this heading">#</a></h1>
<img alt="_images/metatree_example1.png" src="_images/metatree_example1.png" />
<img alt="_images/metatree_example2.png" src="_images/metatree_example2.png" />
<section id="module-bayesml.metatree">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-bayesml.metatree" title="Link to this heading">#</a></h2>
<section id="stochastic-data-generative-model">
<h3>Stochastic Data Generative Model<a class="headerlink" href="#stochastic-data-generative-model" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}=[x_1, \ldots, x_p, x_{p+1}, \ldots , x_{p+q}]\)</span> : an explanatory variable. The first <span class="math notranslate nohighlight">\(p\)</span> variables are continuous. The other <span class="math notranslate nohighlight">\(q\)</span> variables are categorical.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> : a space of an objective variable</p></li>
<li><p><span class="math notranslate nohighlight">\(y \in \mathcal{Y}\)</span> : an objective variable</p></li>
<li><p><span class="math notranslate nohighlight">\(D_\mathrm{max} \in \mathbb{N}\)</span> : the maximum depth of trees</p></li>
<li><p><span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span> : the perfect tree where all the inner nodes have the same number of child nodes and all the leaf nodes have the same depth of <span class="math notranslate nohighlight">\(D_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{S}_\mathrm{max}\)</span> : the set of all the nodes of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(s \in \mathcal{S}_\mathrm{max}\)</span> : a node of a tree</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{I}_\mathrm{max} \subset \mathcal{S}_\mathrm{max}\)</span> : the set of all the inner nodes of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}_\mathrm{max} \subset \mathcal{S}_\mathrm{max}\)</span> : the set of all the leaf nodes of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{T}\)</span> : the set of all the pruned subtrees of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T \in \mathcal{T}\)</span> : a pruned subtree of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{I}_T\)</span> : the set of all the inner nodes of <span class="math notranslate nohighlight">\(T\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}_T\)</span> : the set of all the leaf nodes of <span class="math notranslate nohighlight">\(T\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{k}=(k_s)_{s \in \mathcal{I}_\mathrm{max}}\)</span> : indices of the features assigned to inner nodes, i.e., <span class="math notranslate nohighlight">\(k_s \in \{1, 2,\ldots,p+q\}\)</span>. If <span class="math notranslate nohighlight">\(k_s \leq p\)</span>, the node <span class="math notranslate nohighlight">\(s\)</span> has a threshold.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{K}=\{ 1, 2, \ldots , p+q \}^{|\mathcal{I}_\mathrm{max}|}\)</span> : the set of all <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}=(\theta_s)_{s \in \mathcal{S}}\)</span> : parameters assigned to the nodes</p></li>
<li><p><span class="math notranslate nohighlight">\(s_{\boldsymbol{k},T}(\boldsymbol{x}) \in \mathcal{L}_T\)</span> : a leaf node which <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> reaches under <span class="math notranslate nohighlight">\(T\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span></p></li>
</ul>
<div class="math notranslate nohighlight">
\[p(y | \boldsymbol{x}, \boldsymbol{\theta}, T, \boldsymbol{k})=p(y | \theta_{s_{\boldsymbol{k},T}(\boldsymbol{x})})\]</div>
</section>
<section id="prior-distribution">
<h3>Prior Distribution<a class="headerlink" href="#prior-distribution" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(g_s \in [0,1]\)</span> : a hyperparameter assigned to each node <span class="math notranslate nohighlight">\(s \in \mathcal{S}_\mathrm{max}\)</span>. For any leaf node <span class="math notranslate nohighlight">\(s\)</span> of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span>, we assume <span class="math notranslate nohighlight">\(g_s=0\)</span>.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}p(\boldsymbol{k}) &amp;= \frac{1}{|\mathcal{K}|} = \left( \frac{1}{p+q} \right)^{|\mathcal{I}_\mathrm{max}|}, \\
p(T) &amp;= \prod_{s \in \mathcal{I}_T} g_s \prod_{s' \in \mathcal{L}_T} (1-g_{s'}).\end{split}\]</div>
<p>The prior distribution of the parameter <span class="math notranslate nohighlight">\(\theta_s\)</span> is assumed to be a conjugate prior distribution for <span class="math notranslate nohighlight">\(p(y | \theta_s)\)</span> and independent for each node.</p>
</section>
<section id="posterior-distribution">
<h3>Posterior Distribution<a class="headerlink" href="#posterior-distribution" title="Link to this heading">#</a></h3>
<p>The posterior distribution is approximated as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n \in \mathbb{N}\)</span> : a sample size</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}^n = \{ \boldsymbol{x}_1, \boldsymbol{x}_2, \ldots, \boldsymbol{x}_n \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}_{s, \boldsymbol{k}}\)</span> : the explanatory variables of the data points that pass through <span class="math notranslate nohighlight">\(s\)</span> under <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(y^n = \{ y_1, y_2, \ldots, y_n \}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y_{s, \boldsymbol{k}}\)</span> : the objective variables of the data points that pass through <span class="math notranslate nohighlight">\(s\)</span> under <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span>.</p></li>
</ul>
<p>First, the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{k}, T, \boldsymbol{\theta} | \boldsymbol{x}^n, y^n)\)</span> can be decomposed as follows:</p>
<div class="math notranslate nohighlight">
\[p(\boldsymbol{k}, T, \boldsymbol{\theta} | \boldsymbol{x}^n, y^n) = p(\boldsymbol{k} | \boldsymbol{x}^n, y^n) p(T | \boldsymbol{x}^n, y^n, \boldsymbol{k}) p(\boldsymbol{\theta} | \boldsymbol{x}^n, y^n, \boldsymbol{k}, T).\]</div>
<p>For <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, we can exactly calculate the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\theta} | \boldsymbol{x}^n, y^n, \boldsymbol{k}, T)\)</span> because we assumed the conjugate prior distribution.</p>
<p>Also for <span class="math notranslate nohighlight">\(T\)</span>, we can exactly calculate the posterior distribution <span class="math notranslate nohighlight">\(p(T | \boldsymbol{x}^n, y^n, \boldsymbol{k})\)</span> by using the concept called a meta-tree. 
The meta-tree is not a tree but a set of trees where all the trees have the same feature assignment <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span> to their inner nodes. 
The posterior distribution of the trees over the meta-tree defined by <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span> is as follows:</p>
<div class="math notranslate nohighlight">
\[p(T | \boldsymbol{x}^n, y^n, \boldsymbol{k}) = \prod_{s \in \mathcal{I}_T} g_{s|\boldsymbol{x}^n, y^n, \boldsymbol{k}} \prod_{s' \in \mathcal{L}_T} (1-g_{s'|\boldsymbol{x}^n, y^n, \boldsymbol{k}}),\]</div>
<p>where <span class="math notranslate nohighlight">\(g_{s|\boldsymbol{x}^n, y^n, \boldsymbol{k}} \in [0,1]\)</span> can be calculated from <span class="math notranslate nohighlight">\(\boldsymbol{x}^n\)</span>, <span class="math notranslate nohighlight">\(y^n\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}g_{s|\boldsymbol{x}^n, y^n, \boldsymbol{k}} =
\begin{cases}
    \frac{g_s \prod_{s' \in \mathrm{Ch}(s)}q(y_{s', \boldsymbol{k}}|\boldsymbol{x}_{s', \boldsymbol{k}}, s', \boldsymbol{k})}{q(y_{s, \boldsymbol{k}}|\boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k})}, &amp; s \in \mathcal{I}_\mathrm{max},\\
    g_s, &amp; \mathrm{otherwise},
\end{cases}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathrm{Ch}(s)\)</span> denotes the set of child nodes of <span class="math notranslate nohighlight">\(s\)</span> on <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span> and <span class="math notranslate nohighlight">\(q(y_{s, \boldsymbol{k}}|\boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k})\)</span> is defined for any <span class="math notranslate nohighlight">\(s \in \mathcal{S}_\mathrm{max}\)</span> as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;q(y_{s, \boldsymbol{k}}|\boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k}) =
\begin{cases}
    (1-g_s) f(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k}) \\
    \qquad {}+ g_s \prod_{s' \in \mathrm{Ch}(s)} q(y_{s', \boldsymbol{k}} | \boldsymbol{x}_{s', \boldsymbol{k}}, s', \boldsymbol{k}), &amp; s \in \mathcal{I}_\mathrm{max},\\
    f(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k}), &amp; \mathrm{otherwise}.
\end{cases}\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(f(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k})\)</span> is defined as follows:</p>
<div class="math notranslate nohighlight">
\[f(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k}) = \int p(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, \theta_s) p(\theta_s) \mathrm{d}\theta_s.\]</div>
<p>For <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span>, there are two algirithms to approximate the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{k} | \boldsymbol{x}^n, y^n)\)</span>: the meta-tree random forest (MTRF) and the meta-tree Markov chain Monte Carlo (MTMCMC) method.</p>
<section id="approximation-by-mtrf">
<h4>Approximation by MTRF<a class="headerlink" href="#approximation-by-mtrf" title="Link to this heading">#</a></h4>
<p>In MTRF, we first construct a set of feature assignment vectors <span class="math notranslate nohighlight">\(\mathcal{K}' = \{\boldsymbol{k}_1, \boldsymbol{k}_2, \ldots, \boldsymbol{k}_B\}\)</span> by using the usual (non-Bayesian) random forest algorithm.
Next, for <span class="math notranslate nohighlight">\(\boldsymbol{k} \in \mathcal{K}\)</span>, we approximate the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{k} | \boldsymbol{x}^n, y^n)\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p(\boldsymbol{k} | \boldsymbol{x}^n, y^n) \approx \tilde{p}(\boldsymbol{k} | \boldsymbol{x}^n, y^n) \propto \begin{cases}
    q(y_{s_\lambda, \boldsymbol{k}}|\boldsymbol{x}_{s_\lambda, \boldsymbol{k}}, s_\lambda, \boldsymbol{k}), &amp; \boldsymbol{k} \in \mathcal{K}',\\
    0, &amp; \mathrm{otherwise}.
\end{cases}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(s_{\lambda}\)</span> is the root node of <span class="math notranslate nohighlight">\(T_\mathrm{max}\)</span>.</p>
<p>The predictive distribution is approximated as follows:</p>
<div class="math notranslate nohighlight">
\[p(y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n) = \sum_{\boldsymbol{k} \in \mathcal{K}'} \tilde{p}(\boldsymbol{k} | \boldsymbol{x}^n, y^n) q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\lambda, \boldsymbol{k}),\]</div>
<p>where <span class="math notranslate nohighlight">\(q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\lambda, \boldsymbol{k})\)</span> is calculated in a similar manner to <span class="math notranslate nohighlight">\(q(y_{s_\lambda, \boldsymbol{k}}|\boldsymbol{x}_{s_\lambda, \boldsymbol{k}}, s_\lambda, \boldsymbol{k})\)</span>.</p>
<p>The expectation of the predictive distribution is approximated as follows.</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{p(y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n)} [Y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n] = \sum_{\boldsymbol{k} \in \mathcal{K}'} \tilde{p}(\boldsymbol{k} | \boldsymbol{x}^n, y^n) \mathbb{E}_{q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\lambda, \boldsymbol{k})} [Y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}],\]</div>
<p>where the expectation for <span class="math notranslate nohighlight">\(q\)</span> is recursively given as follows.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;\mathbb{E}_{q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s, \boldsymbol{k})} [Y_{n+1} | \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}] \\
&amp;= \begin{cases}
(1-g_{s|\boldsymbol{x}^n, y^n, \boldsymbol{k}}) \mathbb{E}_{f(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s, \boldsymbol{k})} [Y_{n+1} | \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}] \\
\qquad + g_{s|\boldsymbol{x}^n, y^n, \boldsymbol{k}} \mathbb{E}_{q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\mathrm{child}, \boldsymbol{k})} [Y_{n+1} | \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}] ,&amp; s \in \mathcal{I}_\mathrm{max},\\
\mathbb{E}_{f(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s, \boldsymbol{k})} [Y_{n+1} | \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}],&amp; (\mathrm{otherwise}).
\end{cases}\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(f(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s, \boldsymbol{k})\)</span> is calculated in a similar manner to <span class="math notranslate nohighlight">\(f(y_{s, \boldsymbol{k}} | \boldsymbol{x}_{s, \boldsymbol{k}}, s, \boldsymbol{k})\)</span> and <span class="math notranslate nohighlight">\(s_\mathrm{child}\)</span> is the child node of <span class="math notranslate nohighlight">\(s\)</span> on the path from the root node to the leaf node <span class="math notranslate nohighlight">\(s_{\boldsymbol{k},T_\mathrm{max}}(\boldsymbol{x}_{n+1})\)</span>.</p>
</section>
<section id="approximation-by-mtmcmc">
<h4>Approximation by MTMCMC<a class="headerlink" href="#approximation-by-mtmcmc" title="Link to this heading">#</a></h4>
<p>In MTMCMC method, we generate a sample <span class="math notranslate nohighlight">\(\boldsymbol{k}\)</span> from the posterior distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{k} | \boldsymbol{x}^n, y^n)\)</span> by a MCMC method, and the posterior distribution is approximated by the empirical distribution of this sample.
Let <span class="math notranslate nohighlight">\(\{\boldsymbol{k}^{(t)}\}_{t=1}^{t_\mathrm{end}}\)</span> be the obtained sample.</p>
<p>The predictive distribution is approximated as follows:</p>
<div class="math notranslate nohighlight">
\[p(y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n) = \frac{1}{t_\mathrm{end}} \sum_{t=1}^{t_\mathrm{end}} q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\lambda, \boldsymbol{k}^{(t)}).\]</div>
<p>The expectation of the predictive distribution is approximated as follows:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{p(y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n)} [Y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n] = \frac{1}{t_\mathrm{end}} \sum_{t=1}^{t_\mathrm{end}} \mathbb{E}_{q(y_{n+1}|\boldsymbol{x}_{n+1},\boldsymbol{x}^n, y^n, s_\lambda, \boldsymbol{k}^{(t)})} [Y_{n+1}| \boldsymbol{x}_{n+1}, \boldsymbol{x}^n, y^n, \boldsymbol{k}^{(t)}].\]</div>
</section>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Dobashi, N.; Saito, S.; Nakahara, Y.; Matsushima, T. Meta-Tree Random Forest: Probabilistic Data-Generative Model and Bayes Optimal Prediction. <em>Entropy</em> 2021, 23, 768. <a class="reference external" href="https://doi.org/10.3390/e23060768">https://doi.org/10.3390/e23060768</a></p></li>
<li><p>Nakahara, Y.; Saito, S.; Kamatsuka, A.; Matsushima, T. Probability Distribution on Full Rooted Trees. <em>Entropy</em> 2022, 24, 328. <a class="reference external" href="https://doi.org/10.3390/e24030328">https://doi.org/10.3390/e24030328</a></p></li>
<li><p>Nakahara, Y.; Saito, S.; Ichijo, N.; Kazama, K.; Matsushima, T. Bayesian Decision Theory on Decision Trees: Uncertainty Evaluation and Interpretability. <em>Proceedings of The 28th International Conference on Artificial Intelligence and Statistics</em>, in <em>Proceedings of Machine Learning Research</em> 2025, 258:1045-1053 Available from <a class="reference external" href="https://proceedings.mlr.press/v258/nakahara25a.html">https://proceedings.mlr.press/v258/nakahara25a.html</a>.</p></li>
</ul>
</section>
<dl class="py class">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayesml.metatree.</span></span><span class="sig-name descname"><span class="pre">GenModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">c_dim_continuous</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_dim_categorical</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_max_depth=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_num_children_vec=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_num_assignment_vec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_ranges=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">SubModel=&lt;module</span> <span class="pre">'bayesml.bernoulli'</span> <span class="pre">from</span> <span class="pre">'/Users/nakahara/Documents/GitHub/BayesML/bayesml/bernoulli/__init__.py'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_constants={}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_k_weight_vec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_g=0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_h_params={}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_metatree_list=[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_metatree_prob_vec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="bayesml.html#bayesml.base.Generative" title="bayesml.base.Generative"><code class="xref py py-class docutils literal notranslate"><span class="pre">Generative</span></code></a></p>
<p>The stochastice data generative model and the prior distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>c_dim_continuous</strong><span class="classifier">int</span></dt><dd><p>A non-negative integer</p>
</dd>
<dt><strong>c_dim_categorical</strong><span class="classifier">int</span></dt><dd><p>A non-negative integer</p>
</dd>
<dt><strong>c_num_children_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive integers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, by default [2,2,…,2].
The first <code class="docutils literal notranslate"><span class="pre">c_dim_continuous</span></code> elements represent 
the numbers of children of continuous features at 
inner nodes. The other <code class="docutils literal notranslate"><span class="pre">c_dim_categorial</span></code> elements 
represent those of categorical features.
If a single integer is input, it will be broadcasted.</p>
</dd>
<dt><strong>c_max_depth</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default 2</p>
</dd>
<dt><strong>c_num_assignment_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive integers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>. 
The first <code class="docutils literal notranslate"><span class="pre">c_dim_continuous</span></code> elements represent 
the maximum assignment numbers of continuous features 
on a path. The other <code class="docutils literal notranslate"><span class="pre">c_dim_categorial</span></code> elements 
represent those of categorical features. If it 
has a negative element (e.g., -1), the corresponding 
feature will be assigned any number of times. 
By default [-1,…,-1].</p>
</dd>
<dt><strong>c_ranges</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A numpy.ndarray whose size is (c_dim_continuous,2).
A threshold for the <code class="docutils literal notranslate"><span class="pre">k</span></code>-th continuous feature will be 
generated between <code class="docutils literal notranslate"><span class="pre">c_ranges[k,0]</span></code> and <code class="docutils literal notranslate"><span class="pre">c_ranges[k,1]</span></code>. 
By default, [[-3,3],[-3,3],…,[-3,3]].</p>
</dd>
<dt><strong>SubModel</strong><span class="classifier">class, optional</span></dt><dd><p>bernoulli, categorical, poisson, normal, exponential, 
or linearregression, by default bernoulli</p>
</dd>
<dt><strong>sub_constants</strong><span class="classifier">dict, optional</span></dt><dd><p>constants for self.SubModel.GenModel, by default {}</p>
</dd>
<dt><strong>root</strong><span class="classifier">metatree._Node, optional</span></dt><dd><p>A root node of a meta-tree, 
by default a tree consists of only one node.</p>
</dd>
<dt><strong>h_k_weight_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, 
by default [1,…,1].</p>
</dd>
<dt><strong>h_g</strong><span class="classifier">float, optional</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span>, by default 0.5</p>
</dd>
<dt><strong>sub_h_params</strong><span class="classifier">dict, optional</span></dt><dd><p>h_params for self.SubModel.GenModel, by default {}</p>
</dd>
<dt><strong>h_metatree_list</strong><span class="classifier">list of metatree._Node, optional</span></dt><dd><p>Root nodes of meta-trees, by default []</p>
</dd>
<dt><strong>h_metatree_prob_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of h_metatree_list, 
by default uniform distribution
Sum of its elements must be 1.0.</p>
</dd>
<dt><strong>seed</strong><span class="classifier">{None, int}, optional</span></dt><dd><p>A seed to initialize numpy.random.default_rng(),
by default None</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>c_dim_features: int</strong></dt><dd><p>c_dim_continuous + c_dim_categorical</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.gen_params" title="bayesml.metatree.GenModel.gen_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gen_params</span></code></a>([feature_fix, threshold_fix, ...])</p></td>
<td><p>Generate the parameter from the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.gen_sample" title="bayesml.metatree.GenModel.gen_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gen_sample</span></code></a>([sample_size, x_continuous, ...])</p></td>
<td><p>Generate a sample from the stochastic data generative model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.get_constants" title="bayesml.metatree.GenModel.get_constants"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_constants</span></code></a>()</p></td>
<td><p>Get constants of GenModel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.get_h_params" title="bayesml.metatree.GenModel.get_h_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_h_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.get_params" title="bayesml.metatree.GenModel.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>()</p></td>
<td><p>Get the parameter of the sthocastic data generative model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_h_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to h_params.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_params</span></code>(filename)</p></td>
<td><p>Load the parameters saved by <code class="docutils literal notranslate"><span class="pre">save_params</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_h_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_params</span></code>(filename)</p></td>
<td><p>Save the parameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.save_sample" title="bayesml.metatree.GenModel.save_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_sample</span></code></a>(filename, sample_size[, x])</p></td>
<td><p>Save the generated sample as NumPy <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.set_h_params" title="bayesml.metatree.GenModel.set_h_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_h_params</span></code></a>([h_k_weight_vec, h_g, ...])</p></td>
<td><p>Set the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.set_params" title="bayesml.metatree.GenModel.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>([root])</p></td>
<td><p>Set the parameter of the sthocastic data generative model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.GenModel.visualize_model" title="bayesml.metatree.GenModel.visualize_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">visualize_model</span></code></a>([filename, format, ...])</p></td>
<td><p>Visualize the stochastic data generative model and generated samples.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.get_constants">
<span class="sig-name descname"><span class="pre">get_constants</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.get_constants" title="Link to this definition">#</a></dt>
<dd><p>Get constants of GenModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>constants</strong><span class="classifier">dict of {str: int, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_dim_continuous&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_dim_continuous</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_dim_categorical&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_dim_categorical</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_children_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_children_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_max_depth&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_max_depth</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_assignment_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_assignment_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_ranges&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_ranges</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.set_h_params">
<span class="sig-name descname"><span class="pre">set_h_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h_k_weight_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_g</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_h_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_metatree_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_metatree_prob_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.set_h_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h_k_weight_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, 
by default None.</p>
</dd>
<dt><strong>h_g</strong><span class="classifier">float, optional</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span>, by default None</p>
</dd>
<dt><strong>sub_h_params</strong><span class="classifier">dict, optional</span></dt><dd><p>h_params for self.SubModel.GenModel, by default None</p>
</dd>
<dt><strong>h_metatree_list</strong><span class="classifier">list of metatree._Node, optional</span></dt><dd><p>Root nodes of meta-trees, by default None</p>
</dd>
<dt><strong>h_metatree_prob_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of h_metatree_list, 
by default None.
Sum of its elements must be 1.0.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.get_h_params">
<span class="sig-name descname"><span class="pre">get_h_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.get_h_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h_params</strong><span class="classifier">dict of {str: float, list, dict, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_k_weight_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h_k_weight_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_g&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h_g</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;sub_h_params&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.sub_h_params</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_metatree_list&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h_metatree_list</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h_metatree_prob_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h_metatree_prob_vec</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.gen_params">
<span class="sig-name descname"><span class="pre">gen_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_fix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_fix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_fix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'even'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.gen_params" title="Link to this definition">#</a></dt>
<dd><p>Generate the parameter from the prior distribution.</p>
<p>The generated vaule is set at <code class="docutils literal notranslate"><span class="pre">self.root</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_fix</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, feature assignment indices will be fixed, by default <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>threshold_fix</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, thresholds for continuous features will be fixed, by default <code class="docutils literal notranslate"><span class="pre">False</span></code>. 
If <code class="docutils literal notranslate"><span class="pre">feature_fix</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, <code class="docutils literal notranslate"><span class="pre">threshold_fix</span></code> must be <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>tree_fix</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, tree shape will be fixed, by default <code class="docutils literal notranslate"><span class="pre">False</span></code>. 
If <code class="docutils literal notranslate"><span class="pre">feature_fix</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, <code class="docutils literal notranslate"><span class="pre">tree_fix</span></code> must be <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</dd>
<dt><strong>threshold_type</strong><span class="classifier">{‘even’, ‘random’}, optional</span></dt><dd><p>A type of threshold generating procedure, by default <code class="docutils literal notranslate"><span class="pre">'even'</span></code>
If <code class="docutils literal notranslate"><span class="pre">'even'</span></code>, self.c_ranges will be recursively divided by equal intervals. 
if <code class="docutils literal notranslate"><span class="pre">'random'</span></code>, self.c_ranges will be recursively divided by at random intervals.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.set_params" title="Link to this definition">#</a></dt>
<dd><p>Set the parameter of the sthocastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>root</strong><span class="classifier">metatree._Node, optional</span></dt><dd><p>A root node of a meta-tree, by default None.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.get_params" title="Link to this definition">#</a></dt>
<dd><p>Get the parameter of the sthocastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict of {str:metatree._Node}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;root&quot;</span></code> : The value of <code class="docutils literal notranslate"><span class="pre">self.root</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.gen_sample">
<span class="sig-name descname"><span class="pre">gen_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.gen_sample" title="Link to this definition">#</a></dt>
<dd><p>Generate a sample from the stochastic data generative model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample_size</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>.
Each element x_categorical[i,j] must satisfies 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>1 dimensional array whose size is <code class="docutils literal notranslate"><span class="pre">sample_size</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.save_sample">
<span class="sig-name descname"><span class="pre">save_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.save_sample" title="Link to this definition">#</a></dt>
<dd><p>Save the generated sample as NumPy <code class="docutils literal notranslate"><span class="pre">.npz</span></code> format.</p>
<p>It is saved as a NpzFile with keyword: “x”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename</strong><span class="classifier">str</span></dt><dd><p>The filename to which the sample is saved.
<code class="docutils literal notranslate"><span class="pre">.npz</span></code> will be appended if it isn’t there.</p>
</dd>
<dt><strong>sample_size</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.savez_compressed.html#numpy.savez_compressed" title="(in NumPy v2.2)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.savez_compressed</span></code></a></dt><dd></dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.GenModel.visualize_model">
<span class="sig-name descname"><span class="pre">visualize_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.GenModel.visualize_model" title="Link to this definition">#</a></dt>
<dd><p>Visualize the stochastic data generative model and generated samples.</p>
<p>Note that values of categorical features will be shown with jitters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename</strong><span class="classifier">str, optional</span></dt><dd><p>Filename for saving the figure, by default <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt><strong>format</strong><span class="classifier">str, optional</span></dt><dd><p>Rendering output format (<code class="docutils literal notranslate"><span class="pre">&quot;pdf&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;png&quot;</span></code>, …).</p>
</dd>
<dt><strong>sample_size</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default 100</p>
</dd>
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#graphviz.Digraph" title="(in graphviz)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">graphviz.Digraph</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bayesml</span><span class="w"> </span><span class="kn">import</span> <span class="n">metatree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">metatree</span><span class="o">.</span><span class="n">GenModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_continuous</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_categorical</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">gen_params</span><span class="p">(</span><span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">visualize_model</span><span class="p">()</span>
</pre></div>
</div>
<img alt="_images/metatree_example1.png" src="_images/metatree_example1.png" />
<img alt="_images/metatree_example2.png" src="_images/metatree_example2.png" />
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bayesml.metatree.</span></span><span class="sig-name descname"><span class="pre">LearnModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">c_dim_continuous</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_dim_categorical</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_max_depth=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_num_children_vec=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_num_assignment_vec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_ranges=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">SubModel=&lt;module</span> <span class="pre">'bayesml.bernoulli'</span> <span class="pre">from</span> <span class="pre">'/Users/nakahara/Documents/GitHub/BayesML/bayesml/bernoulli/__init__.py'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_constants={}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_k_weight_vec=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_g=0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_h0_params={}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_metatree_list=[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_metatree_prob_vec=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel" title="Link to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="bayesml.html#bayesml.base.Posterior" title="bayesml.base.Posterior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Posterior</span></code></a>, <a class="reference internal" href="bayesml.html#bayesml.base.PredictiveMixin" title="bayesml.base.PredictiveMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredictiveMixin</span></code></a></p>
<p>The posterior distribution and the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>c_dim_continuous</strong><span class="classifier">int</span></dt><dd><p>A non-negative integer</p>
</dd>
<dt><strong>c_dim_categorical</strong><span class="classifier">int</span></dt><dd><p>A non-negative integer</p>
</dd>
<dt><strong>c_max_depth</strong><span class="classifier">int, optional</span></dt><dd><p>A positive integer, by default 2</p>
</dd>
<dt><strong>c_num_children_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive integers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, by default [2,2,…,2].
The first <code class="docutils literal notranslate"><span class="pre">c_dim_continuous</span></code> elements represent 
the numbers of children of continuous features at 
inner nodes. The other <code class="docutils literal notranslate"><span class="pre">c_dim_categorial</span></code> elements 
represent those of categorical features.
If a single integer is input, it will be broadcasted.</p>
</dd>
<dt><strong>c_num_assignment_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive integers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>. 
The first <code class="docutils literal notranslate"><span class="pre">c_dim_continuous</span></code> elements represent 
the maximum assignment numbers of continuous features 
on a path. The other <code class="docutils literal notranslate"><span class="pre">c_dim_categorial</span></code> elements 
represent those of categorical features. If it 
has a negative element (e.g., -1), the corresponding 
feature will be assigned any number of times. 
By default [-1,…,-1].</p>
</dd>
<dt><strong>c_ranges</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A numpy.ndarray whose size is (c_dim_continuous,2).
A threshold for the <code class="docutils literal notranslate"><span class="pre">k</span></code>-th continuous feature will be 
generated between <code class="docutils literal notranslate"><span class="pre">c_ranges[k,0]</span></code> and <code class="docutils literal notranslate"><span class="pre">c_ranges[k,1]</span></code>. 
By default, [[-3,3],[-3,3],…,[-3,3]].</p>
</dd>
<dt><strong>SubModel</strong><span class="classifier">class, optional</span></dt><dd><p>bernoulli, categorical, poisson, normal, exponential, 
or linearregression, by default bernoulli</p>
</dd>
<dt><strong>sub_constants</strong><span class="classifier">dict, optional</span></dt><dd><p>constants for self.SubModel.LearnModel, by default {}</p>
</dd>
<dt><strong>h0_k_weight_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, 
by default [1,…,1].</p>
</dd>
<dt><strong>h0_g</strong><span class="classifier">float, optional</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span>, by default 0.5</p>
</dd>
<dt><strong>sub_h0_params</strong><span class="classifier">dict, optional</span></dt><dd><p>h0_params for self.SubModel.LearnModel, by default {}</p>
</dd>
<dt><strong>h0_metatree_list</strong><span class="classifier">list of metatree._Node, optional</span></dt><dd><p>Root nodes of meta-trees, by default []</p>
</dd>
<dt><strong>h0_metatree_prob_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of h0_metatree_list, 
by default uniform distribution
Sum of its elements must be 1.0.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>c_dim_features: int</strong></dt><dd><p>c_dim_continuous + c_dim_categorical</p>
</dd>
<dt><strong>hn_k_weight_vec</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code></p>
</dd>
<dt><strong>hn_g</strong><span class="classifier">float</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span></p>
</dd>
<dt><strong>sub_hn_params</strong><span class="classifier">dict</span></dt><dd><p>hn_params for self.SubModel.LearnModel</p>
</dd>
<dt><strong>hn_metatree_list</strong><span class="classifier">list of metatree._Node</span></dt><dd><p>Root nodes of meta-trees</p>
</dd>
<dt><strong>hn_metatree_prob_vec</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of h0_metatree_list.
Sum of its elements is 1.0.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<div class="pst-scrollable-table-container"><table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.calc_feature_importances" title="bayesml.metatree.LearnModel.calc_feature_importances"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calc_feature_importances</span></code></a>()</p></td>
<td><p>Calculate the feature importances</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.calc_pred_density" title="bayesml.metatree.LearnModel.calc_pred_density"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calc_pred_density</span></code></a>(y)</p></td>
<td><p>Calculate the values of the probability density function of the predictive distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.calc_pred_dist" title="bayesml.metatree.LearnModel.calc_pred_dist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calc_pred_dist</span></code></a>([x_continuous, x_categorical])</p></td>
<td><p>Calculate the parameters of the predictive distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.calc_pred_var" title="bayesml.metatree.LearnModel.calc_pred_var"><code class="xref py py-obj docutils literal notranslate"><span class="pre">calc_pred_var</span></code></a>()</p></td>
<td><p>Calculate the variance of the predictive distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.estimate_params" title="bayesml.metatree.LearnModel.estimate_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_params</span></code></a>([loss, visualize, filename, ...])</p></td>
<td><p>Estimate the parameter under the given criterion.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.fit" title="bayesml.metatree.LearnModel.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>([x_continuous, x_categorical, y, alg_type])</p></td>
<td><p>Fit the model to the data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.get_constants" title="bayesml.metatree.LearnModel.get_constants"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_constants</span></code></a>()</p></td>
<td><p>Get constants of LearnModel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.get_h0_params" title="bayesml.metatree.LearnModel.get_h0_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_h0_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.get_hn_params" title="bayesml.metatree.LearnModel.get_hn_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_hn_params</span></code></a>()</p></td>
<td><p>Get the hyperparameters of the posterior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.get_p_params" title="bayesml.metatree.LearnModel.get_p_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_p_params</span></code></a>()</p></td>
<td><p>Get the parameters of the predictive distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_h0_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to h0_params.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_hn_params</span></code>(filename)</p></td>
<td><p>Load the hyperparameters to hn_params.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.make_prediction" title="bayesml.metatree.LearnModel.make_prediction"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_prediction</span></code></a>([loss])</p></td>
<td><p>Predict a new data point under the given criterion.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">overwrite_h0_params</span></code>()</p></td>
<td><p>Overwrite the initial values of the hyperparameters of the posterior distribution by the learned values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.pred_and_update" title="bayesml.metatree.LearnModel.pred_and_update"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pred_and_update</span></code></a>([x_continuous, ...])</p></td>
<td><p>Predict a new data point and update the posterior sequentially.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.predict" title="bayesml.metatree.LearnModel.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>([x_continuous, x_categorical])</p></td>
<td><p>Predict the data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.predict_proba" title="bayesml.metatree.LearnModel.predict_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_proba</span></code></a>([x_continuous, x_categorical])</p></td>
<td><p>Predict the data.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_hn_params</span></code>()</p></td>
<td><p>Reset the hyperparameters of the posterior distribution to their initial values.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_h0_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_hn_params</span></code>(filename)</p></td>
<td><p>Save the hyperparameters using python <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.set_h0_params" title="bayesml.metatree.LearnModel.set_h0_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_h0_params</span></code></a>([h0_k_weight_vec, h0_g, ...])</p></td>
<td><p>Set the hyperparameters of the prior distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.set_hn_params" title="bayesml.metatree.LearnModel.set_hn_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_hn_params</span></code></a>([hn_k_weight_vec, hn_g, ...])</p></td>
<td><p>Set the hyperparameters of the posterior distribution.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.update_posterior" title="bayesml.metatree.LearnModel.update_posterior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">update_posterior</span></code></a>([x_continuous, ...])</p></td>
<td><p>Update the hyperparameters of the posterior distribution using traning data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bayesml.metatree.LearnModel.visualize_posterior" title="bayesml.metatree.LearnModel.visualize_posterior"><code class="xref py py-obj docutils literal notranslate"><span class="pre">visualize_posterior</span></code></a>([filename, format, ...])</p></td>
<td><p>Visualize the posterior distribution for the parameter.</p></td>
</tr>
</tbody>
</table>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.get_constants">
<span class="sig-name descname"><span class="pre">get_constants</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.get_constants" title="Link to this definition">#</a></dt>
<dd><p>Get constants of LearnModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>constants</strong><span class="classifier">dict of {str: int, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_dim_continuous&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_dim_continuous</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_dim_categorical&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_dim_categorical</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_children_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_children_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_max_depth&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_max_depth</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_num_assignment_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_num_assignment_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;c_ranges&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.c_ranges</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.set_h0_params">
<span class="sig-name descname"><span class="pre">set_h0_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">h0_k_weight_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_g</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_h0_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_metatree_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h0_metatree_prob_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.set_h0_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h0_k_weight_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, 
by default None.</p>
</dd>
<dt><strong>h0_g</strong><span class="classifier">float, optional</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span>, by default None</p>
</dd>
<dt><strong>sub_h0_params</strong><span class="classifier">dict, optional</span></dt><dd><p>h0_params for self.SubModel.LearnModel, by default None</p>
</dd>
<dt><strong>h0_metatree_list</strong><span class="classifier">list of metatree._Node, optional</span></dt><dd><p>Root nodes of meta-trees, by default None</p>
</dd>
<dt><strong>h0_metatree_prob_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of h0_metatree_list, 
by default None.
Sum of its elements must be 1.0.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.get_h0_params">
<span class="sig-name descname"><span class="pre">get_h0_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.get_h0_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the prior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>h0_params</strong><span class="classifier">dict of {str: float, list, dict, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_k_weight_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_k_weight_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_g&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_g</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;sub_h0_params&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.sub_h0_params</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_metatree_list&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_metatree_list</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;h0_metatree_prob_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.h0_metatree_prob_vec</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.set_hn_params">
<span class="sig-name descname"><span class="pre">set_hn_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hn_k_weight_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_g</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sub_hn_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_metatree_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hn_metatree_prob_vec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.set_hn_params" title="Link to this definition">#</a></dt>
<dd><p>Set the hyperparameters of the posterior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>hn_k_weight_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of positive real numbers whose length is 
<code class="docutils literal notranslate"><span class="pre">c_dim_continuous+c_dim_categorical</span></code>, 
by default None.</p>
</dd>
<dt><strong>hn_g</strong><span class="classifier">float, optional</span></dt><dd><p>A real number in <span class="math notranslate nohighlight">\([0, 1]\)</span>, by default None</p>
</dd>
<dt><strong>sub_hn_params</strong><span class="classifier">dict, optional</span></dt><dd><p>hn_params for self.SubModel.LearnModel, by default None</p>
</dd>
<dt><strong>hn_metatree_list</strong><span class="classifier">list of metatree._Node, optional</span></dt><dd><p>Root nodes of meta-trees, by default None</p>
</dd>
<dt><strong>hn_metatree_prob_vec</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A vector of real numbers in <span class="math notranslate nohighlight">\([0, 1]\)</span> 
that represents prior distribution of hn_metatree_list, 
by default None.
Sum of its elements must be 1.0.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.get_hn_params">
<span class="sig-name descname"><span class="pre">get_hn_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.get_hn_params" title="Link to this definition">#</a></dt>
<dd><p>Get the hyperparameters of the posterior distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>hn_params</strong><span class="classifier">dict of {str: float, list, dict, numpy.ndarray}</span></dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_k_weight_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_k_weight_vec</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_g&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_g</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;sub_hn_params&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.sub_hn_params</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_metatree_list&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_metatree_list</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;hn_metatree_prob_vec&quot;</span></code> : the value of <code class="docutils literal notranslate"><span class="pre">self.hn_metatree_prob_vec</span></code></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.update_posterior">
<span class="sig-name descname"><span class="pre">update_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MTRF'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.update_posterior" title="Link to this definition">#</a></dt>
<dd><p>Update the hyperparameters of the posterior distribution using traning data.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>values of objective variable whose dtype may be int or float</p>
</dd>
<dt><strong>alg_type</strong><span class="classifier">{‘MTRF’, ‘given_MT’, ‘MTMCMC’, ‘REMTMCMC’}, optional</span></dt><dd><p>type of algorithm, by default ‘MTRF’</p>
</dd>
<dt><strong>**kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>optional parameters of algorithms, by default {}.</p>
<ul>
<li><p>When <code class="docutils literal notranslate"><span class="pre">alg_type='MTRF'</span></code></p>
<ul class="simple">
<li><p>In MTRF[1], <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier</span></code> or 
<code class="docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code> is called as a subroutine. 
Arguments given as <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> are passed to these subroutines. 
Therefore, if you want to specify options for these subroutines, 
e.g., <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> or <code class="docutils literal notranslate"><span class="pre">random_state</span></code>, etc., you can specify them here. 
However, <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> of these subroutines is set to the value of 
<code class="docutils literal notranslate"><span class="pre">self.c_max_depth</span></code>, so if you set it again, you will get an error.</p></li>
</ul>
</li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">alg_type='given_MT'</span></code></p>
<ul class="simple">
<li><p>There are no optional parameters for <code class="docutils literal notranslate"><span class="pre">'given_MT'</span></code>.</p></li>
</ul>
</li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">alg_type='MTMCMC'</span></code></p>
<ul>
<li><p>burn_in : int</p>
<p>The length of the burn-in phase, by default 100.</p>
</li>
<li><p>num_metatrees : int</p>
<p>The number of sampling after burn-in phase, by default 500.</p>
</li>
<li><p>g_max : float</p>
<p>An initial value of a parameter to controll the entropy of the proposal distribution 
in the Metropolis-Hastings step, by default 0.0. See also Appendix B.4 in [2]. 
<code class="docutils literal notranslate"><span class="pre">g_max</span></code> will be tuned in burn-in phase by Algorithm 1 in [2].</p>
</li>
<li><p>rho : float</p>
<p>Parameter of Algorithm 1 in [2], by default 0.99.</p>
</li>
<li><p>phi : float</p>
<p>Parameter of Algorithm 1 in [2], by default 0.999.</p>
</li>
<li><p>p_obj : float</p>
<p>Parameter of Algorithm 1 in [2], by default 0.3. 
<code class="docutils literal notranslate"><span class="pre">p_obj</span></code> corresponds to $r_\mathrm{obj}$ in Algorithm 1 in [2].</p>
</li>
<li><p>threshold_type : {‘1d_kmeans’, ‘sample_midpoint’}</p>
<p>A generating rule of thresholds for continuous explanatory variables, 
by default <code class="docutils literal notranslate"><span class="pre">'1d_kmeans'</span></code>. See also Appendix G in [2].</p>
</li>
<li><p>seed : {None, int}, optional</p>
<p>A seed to initialize numpy.random.default_rng(),
by default None.</p>
</li>
</ul>
</li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">alg_type='REMTMCMC'</span></code></p>
<ul>
<li><p>burn_in : int</p>
<p>The length of the burn-in phase, by default 100.</p>
</li>
<li><p>num_metatrees : int</p>
<p>The number of sampling after burn-in phase, by default 500.</p>
</li>
<li><p>num_chains : int</p>
<p>Number of replicas in replica exchange Monte Carlo Methods, 
by default 8. It corresponds to $J$ in Appendix D in[2]</p>
</li>
<li><p>g_max : float</p>
<p>A parameter to controll the entropy of the proposal distribution 
in the Metropolis-Hastings step, by default 0.9. In contrast to 
MTMCMC, <code class="docutils literal notranslate"><span class="pre">g_max</span></code> tuning is not performed in burn-in phase.
See also Appendix B.4 in [2].</p>
</li>
<li><p>beta_vec : {None, numpy.ndarray}</p>
<p>Temperature parameters for replica exchange Monte Carlo methods, 
by default None. It must satisfy $0 \leq \beta_1 &lt; \beta_2 &lt; \cdots &lt; \beta_J = 1$.
If None, $\beta_j = j/J$. See also Appendix D in [2].</p>
</li>
<li><p>num_interval : int</p>
<p>Length of interval between replica exchange processes, by default 10.
See also Appendix D in [2].</p>
</li>
<li><p>num_exchange : int</p>
<p>Number of replicas exchanged in a single replica exchange process, 
by default 4. See also Appendix D in [2].</p>
</li>
<li><p>threshold_type : {‘1d_kmeans’, ‘sample_midpoint’}</p>
<p>A generating rule of thresholds for continuous explanatory variables, 
by default <code class="docutils literal notranslate"><span class="pre">'1d_kmeans'</span></code>. See also Appendix G in [2].</p>
</li>
<li><p>seed : {None, int}, optional</p>
<p>A seed to initialize numpy.random.default_rng(),
by default None.</p>
</li>
</ul>
</li>
</ul>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" title="(in scikit-learn v1.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier</span></code></a></dt><dd></dd>
<dt><a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="(in scikit-learn v1.6)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestRegressor</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd12bbd48bc8d-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Dobashi, N., Saito, S., Nakahara, Y., &amp; Matsushima, T. (2021). 
Meta-Tree Random Forest: Probabilistic Data-Generative Model and 
Bayes Optimal Prediction. <em>Entropy</em>, 23(6), 768. 
Available from <a class="reference external" href="https://doi.org/10.3390/e23060768">https://doi.org/10.3390/e23060768</a></p>
</div>
<div class="citation" id="rd12bbd48bc8d-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Nakahara, Y., Saito, S., Ichijo, N., Kazama, K. &amp; Matsushima, T. (2025). 
Bayesian Decision Theory on Decision Trees: Uncertainty Evaluation and Interpretability. 
<em>Proceedings of The 28th International Conference on Artificial Intelligence and Statistics</em>, 
in <em>Proceedings of Machine Learning Research</em> 258:1045-1053 
Available from <a class="reference external" href="https://proceedings.mlr.press/v258/nakahara25a.html">https://proceedings.mlr.press/v258/nakahara25a.html</a>.</p>
</div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.estimate_params">
<span class="sig-name descname"><span class="pre">estimate_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'0-1'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visualize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.estimate_params" title="Link to this definition">#</a></dt>
<dd><p>Estimate the parameter under the given criterion.</p>
<p>The approximate MAP meta-tree 
<span class="math notranslate nohighlight">\(M_{T,\boldsymbol{k}_b} = \mathrm{argmax} p(M_{T,\boldsymbol{k}_{b'}} | \boldsymbol{x}^n, y^n)\)</span> 
will be returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default <code class="docutils literal notranslate"><span class="pre">&quot;0-1&quot;</span></code>.
This function supports only <code class="docutils literal notranslate"><span class="pre">&quot;0-1&quot;</span></code>.</p>
</dd>
<dt><strong>visualize</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the estimated metatree will be visualized, by default <code class="docutils literal notranslate"><span class="pre">True</span></code>.
This visualization requires <code class="docutils literal notranslate"><span class="pre">graphviz</span></code>.</p>
</dd>
<dt><strong>filename</strong><span class="classifier">str, optional</span></dt><dd><p>Filename for saving the figure, by default <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt><strong>format</strong><span class="classifier">str, optional</span></dt><dd><p>Rendering output format (<code class="docutils literal notranslate"><span class="pre">&quot;pdf&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;png&quot;</span></code>, …).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>map_root</strong><span class="classifier">metatree._Node</span></dt><dd><p>The root node of the estimated meta-tree 
that also contains the estimated parameters in each node.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Multiple metatrees can represent equivalent model classes. 
This function does not take such duplication into account.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#graphviz.Digraph" title="(in graphviz)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">graphviz.Digraph</span></code></a></dt><dd></dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.visualize_posterior">
<span class="sig-name descname"><span class="pre">visualize_posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_metatrees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.visualize_posterior" title="Link to this definition">#</a></dt>
<dd><p>Visualize the posterior distribution for the parameter.</p>
<p>This method requires <code class="docutils literal notranslate"><span class="pre">graphviz</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>filename</strong><span class="classifier">str, optional</span></dt><dd><p>Filename for saving the figure, by default <code class="docutils literal notranslate"><span class="pre">None</span></code></p>
</dd>
<dt><strong>format</strong><span class="classifier">str, optional</span></dt><dd><p>Rendering output format (<code class="docutils literal notranslate"><span class="pre">&quot;pdf&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;png&quot;</span></code>, …).</p>
</dd>
<dt><strong>num_metatrees</strong><span class="classifier">int, optional</span></dt><dd><p>Number of metatrees to be visualized, by default 3.</p>
</dd>
<dt><strong>h_params</strong><span class="classifier">bool, optional</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, hyperparameters at each node will be visualized. 
if <code class="docutils literal notranslate"><span class="pre">False</span></code>, estimated parameters at each node will be visulaized.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference external" href="https://graphviz.readthedocs.io/en/stable/api.html#graphviz.Digraph" title="(in graphviz)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">graphviz.Digraph</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">bayesml</span><span class="w"> </span><span class="kn">import</span> <span class="n">metatree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gen_model</span> <span class="o">=</span> <span class="n">metatree</span><span class="o">.</span><span class="n">GenModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_continuous</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_categorical</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gen_model</span><span class="o">.</span><span class="n">gen_params</span><span class="p">(</span><span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;random&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x_continuous</span><span class="p">,</span><span class="n">x_categorical</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">gen_model</span><span class="o">.</span><span class="n">gen_sample</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span> <span class="o">=</span> <span class="n">metatree</span><span class="o">.</span><span class="n">LearnModel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_continuous</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">c_dim_categorical</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span><span class="o">.</span><span class="n">update_posterior</span><span class="p">(</span><span class="n">x_continuous</span><span class="p">,</span><span class="n">x_categorical</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learn_model</span><span class="o">.</span><span class="n">visualize_posterior</span><span class="p">(</span><span class="n">num_metatrees</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/metatree_posterior2.png" src="_images/metatree_posterior2.png" />
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.get_p_params">
<span class="sig-name descname"><span class="pre">get_p_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.get_p_params" title="Link to this definition">#</a></dt>
<dd><p>Get the parameters of the predictive distribution.</p>
<p>This model does not have a simple parametric expression of the predictive distribution.
Therefore, this function returns <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">None</span></code></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.calc_pred_dist">
<span class="sig-name descname"><span class="pre">calc_pred_dist</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.calc_pred_dist" title="Link to this definition">#</a></dt>
<dd><p>Calculate the parameters of the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.make_prediction">
<span class="sig-name descname"><span class="pre">make_prediction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.make_prediction" title="Link to this definition">#</a></dt>
<dd><p>Predict a new data point under the given criterion.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default None.
This function supports “squared”, “0-1”, and “KL”.
If loss is None, “squared” is used when the submodel is a regression model (normal, poisson, exponential, or linear regression), 
and “0-1” is used when the submodel is a classification model (bernoulli or categorical).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>predicted_values</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The predicted values under the given loss function. 
If the submodel is a classification model (bernoulli or categorical) and 
the loss function is “KL”, the predictive distribution will be returned
as numpy.ndarray that consists of occurence probabilities.</p>
<p>The size of the predicted values or the number of predictive distribution is 
the same as the sample size of x_continuous and x_categorical 
when you called calc_pred_dist(x_continuous,x_categorical).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.pred_and_update">
<span class="sig-name descname"><span class="pre">pred_and_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.pred_and_update" title="Link to this definition">#</a></dt>
<dd><p>Predict a new data point and update the posterior sequentially.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>values of objective variable whose dtype may be int or float</p>
</dd>
<dt><strong>loss</strong><span class="classifier">str, optional</span></dt><dd><p>Loss function underlying the Bayes risk function, by default None.
This function supports “squared”, “0-1”, and “KL”.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>predicted_values</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The predicted values under the given loss function. 
If the submodel is a classification model (bernoulli or categorical) and 
the loss function is “KL”, the predictive distribution will be returned
as numpy.ndarray that consists of occurence probabilities.</p>
<p>The size of the predicted values or the number of predictive distribution is 
the same as the sample size of x_continuous and x_categorical 
when you called calc_pred_dist(x_continuous,x_categorical).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.calc_pred_var">
<span class="sig-name descname"><span class="pre">calc_pred_var</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.calc_pred_var" title="Link to this definition">#</a></dt>
<dd><p>Calculate the variance of the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>vars</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The variances of the predictive distribution. 
The size of the vars is the same as the sample size of x when you called calc_pred_dist(x).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.calc_feature_importances">
<span class="sig-name descname"><span class="pre">calc_feature_importances</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.calc_feature_importances" title="Link to this definition">#</a></dt>
<dd><p>Calculate the feature importances</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_importances</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The feature importances.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.calc_pred_density">
<span class="sig-name descname"><span class="pre">calc_pred_density</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.calc_pred_density" title="Link to this definition">#</a></dt>
<dd><p>Calculate the values of the probability density function of the predictive distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>y must have a size that is broadcastable to (sample_size,), i.e., 
the size along the last dimension must be 1 or sample_size.
Here, sample_size is the sample size of x when you called calc_pred_dist(x).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>p_y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The values of the probability density function of the predictive distribution.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alg_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MTRF'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.fit" title="Link to this definition">#</a></dt>
<dd><p>Fit the model to the data.</p>
<p>This function is a wrapper of the following functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">reset_hn_params</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">update_posterior</span><span class="p">(</span><span class="n">x_continuous</span><span class="p">,</span><span class="n">x_categorical</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">alg_type</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>values of objective variable whose dtype may be int or float</p>
</dd>
<dt><strong>alg_type</strong><span class="classifier">{‘MTRF’, ‘given_MT’, ‘MTMCMC’, ‘REMTMCMC’}, optional</span></dt><dd><p>type of algorithm, by default ‘MTRF’</p>
</dd>
<dt><strong>**kwargs</strong><span class="classifier">dict, optional</span></dt><dd><p>optional parameters of algorithms, by default {}</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">LearnModel</span></dt><dd><p>The fitted model.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.predict" title="Link to this definition">#</a></dt>
<dd><p>Predict the data.</p>
<p>This function is a wrapper of the following functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">calc_pred_dist</span><span class="p">(</span><span class="n">x_continuous</span><span class="p">,</span><span class="n">x_categorical</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_prediction</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predicted_values</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>If the submodel is a regression model (normal, poisson, exponential, or linear regression), 
the predicted values under the squared loss function will be returned. 
If the submodel is a classification model (bernoulli or categorical), 
the predicted values under the 0-1 loss function will be returend. 
The size of the predicted values is the same as the sample size of 
x_continuous and x_categorical.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bayesml.metatree.LearnModel.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x_continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_categorical</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bayesml.metatree.LearnModel.predict_proba" title="Link to this definition">#</a></dt>
<dd><p>Predict the data.</p>
<p>This function is supported when the submodel is a classification model (bernoulli or categorical).
It is a wrapper of the following functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">calc_pred_dist</span><span class="p">(</span><span class="n">x_continuous</span><span class="p">,</span><span class="n">x_categorical</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_prediction</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;KL&quot;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x_continuous</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional float array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_continuous)</span></code>, 
by default None.</p>
</dd>
<dt><strong>x_categorical</strong><span class="classifier">numpy.ndarray, optional</span></dt><dd><p>A 2-dimensional int array whose size is <code class="docutils literal notranslate"><span class="pre">(sample_size,c_dim_categorical)</span></code>, 
by default None. Each element x_categorical[i,j] must satisfy 
0 &lt;= x_categorical[i,j] &lt; self.c_num_children_vec[self.c_dim_continuous+j].</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>predicted_distributions</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>The predicted distributions under the KL loss function. 
The number of the predicted distributions is the same as the sample size of 
x_continuous and x_categorical.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bayesml.linearregression.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">bayesml.linearregression package</p>
      </div>
    </a>
    <a class="right-next"
       href="bayesml.multivariate_normal.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">bayesml.multivariate_normal package</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-bayesml.metatree">Module contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-data-generative-model">Stochastic Data Generative Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-distribution">Prior Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-distribution">Posterior Distribution</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation-by-mtrf">Approximation by MTRF</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation-by-mtmcmc">Approximation by MTMCMC</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel"><code class="docutils literal notranslate"><span class="pre">GenModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_constants"><code class="docutils literal notranslate"><span class="pre">GenModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.set_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_h_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_h_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.gen_params"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.set_params"><code class="docutils literal notranslate"><span class="pre">GenModel.set_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.get_params"><code class="docutils literal notranslate"><span class="pre">GenModel.get_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.gen_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.gen_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.save_sample"><code class="docutils literal notranslate"><span class="pre">GenModel.save_sample()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.GenModel.visualize_model"><code class="docutils literal notranslate"><span class="pre">GenModel.visualize_model()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel"><code class="docutils literal notranslate"><span class="pre">LearnModel</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_constants"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_constants()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.set_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_h0_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_h0_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.set_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.set_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_hn_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_hn_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.update_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.update_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.estimate_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.estimate_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.visualize_posterior"><code class="docutils literal notranslate"><span class="pre">LearnModel.visualize_posterior()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.get_p_params"><code class="docutils literal notranslate"><span class="pre">LearnModel.get_p_params()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_dist"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_dist()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.make_prediction"><code class="docutils literal notranslate"><span class="pre">LearnModel.make_prediction()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.pred_and_update"><code class="docutils literal notranslate"><span class="pre">LearnModel.pred_and_update()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_var"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_var()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_feature_importances"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_feature_importances()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.calc_pred_density"><code class="docutils literal notranslate"><span class="pre">LearnModel.calc_pred_density()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.fit"><code class="docutils literal notranslate"><span class="pre">LearnModel.fit()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.predict"><code class="docutils literal notranslate"><span class="pre">LearnModel.predict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesml.metatree.LearnModel.predict_proba"><code class="docutils literal notranslate"><span class="pre">LearnModel.predict_proba()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By BayesML Developers
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, BayesML Developers.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>